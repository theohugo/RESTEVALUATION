Yes bro câ€™est **clean de chez clean**, ta base est nickel ğŸ”¥
On te gÃ©nÃ¨re maintenant un **README clair** + un **.gitignore propre** pour Node/Postgres/Docker.

---

# ğŸ“˜ **README.md â€” Projet KBO (Import + Base Postgres)**

Structure du dossier :

```

RESTEVALUATION/
    docker-compose.yml
    init.sql
    kbo-data/
        activity.csv
        address.csv
        branch.csv
        code.csv
        contact.csv
        denomination.csv
        enterprise.csv
        establishment.csv
        meta.csv

````

---

## â–¶ï¸ Lancer la base de donnÃ©es

```bash
docker compose up -d
````

Cela va :

1. DÃ©marrer PostgreSQL
2. ExÃ©cuter `init.sql`
3. CrÃ©er toutes les tables
4. Importer automatiquement les CSV

---

## ğŸ—ƒï¸ Se connecter Ã  PostgreSQL

```bash
docker exec -it kbo-postgres psql -U kbo -d kbo
```

---

## ğŸ“¦ VÃ©rification rapide

Dans `psql` :

```sql
SELECT COUNT(*) FROM enterprise;
SELECT COUNT(*) FROM branch;
SELECT COUNT(*) FROM establishment;
```

Normalement :

* `enterprise` â‰ˆ **1.9M** lignes
* `branch`, `establishment`, etc. â‰ˆ **100** lignes (limitÃ©es pour test)

---

## ğŸ”„ RÃ©initialiser la base (si besoin)

```bash
docker compose down
rm -rf postgres-data
docker compose up -d
```

âš ï¸ `postgres-data` contient toutes les donnÃ©es â†’ suppression = reset complet.

---

## ğŸ“ Contenu du projet

* **docker-compose.yml**
  Configure PostgreSQL + montage des CSV.

* **init.sql**

  * CrÃ©e toutes les tables
  * Ajoute PK + FK
  * Importe les CSV automatiquement
  * Limite Ã  100 lignes pour les tables hors `enterprise`

---

## ğŸ§© Ã‰tapes suivantes

* DÃ©velopper l'API **Node.js (Express ou Nest)**
* Ajouter Prisma / Sequelize si besoin
* CRUD complet
* Routes relationnelles (enterprise â†’ establishments â†’ branches, etc.)

---

## âœ¨ Auteur

Projet scolaire â€“ Ã©valuation REST API (Hugo)
